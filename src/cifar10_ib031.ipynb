{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition - Classifying images from CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Šimon Varga, Michal Barnišin*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton and are available [here](https://www.cs.toronto.edu/~kriz/cifar.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "def load_all_data():\n",
    "    all_images, all_labels = [], []\n",
    "    for batch_nb in range(1, 6):\n",
    "        imgs, labels = utils.read_data_batch(batch_nb)\n",
    "        all_images.append(imgs)\n",
    "        all_labels.append(labels)\n",
    "    del imgs, labels\n",
    "    all_images = np.concatenate(all_images, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    return all_images, all_labels\n",
    "\n",
    "\n",
    "train_data, train_labels = load_all_data()\n",
    "test_data, test_labels = utils.read_test_batch()\n",
    "labels = utils.read_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 50,000 train images = rows, each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are labeled with numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data. The string representations of labels are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 1 + max(train_labels)):\n",
    "    print(f\"{i}\\t{utils.get_label_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test batch contains exactly 1000 randomly-selected images from each class. \n",
    "\n",
    "As declared, the classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, 9 random pictures follow, and 4 pictures from each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import graphs\n",
    "\n",
    "graphs.plot_random(train_data, train_labels, 3, 3,\n",
    "            fontsize='small', sharey=True, sharex=True, figsize=(3, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    label = labels[i].decode('utf-8')\n",
    "    cat_images = train_data[train_labels == i]\n",
    "    graphs.plot_random(cat_images, [i] * len(cat_images), 1, 4,\n",
    "                       fontsize='small', sharey=True, sharex=True,\n",
    "                       figsize=(4, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"{label}: {len(cat_images)} entries\")\n",
    "del cat_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And average image for each category throughout the whole train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EDA\n",
    "\n",
    "batch = {\n",
    "    b'data': train_data,\n",
    "    b'labels': train_labels\n",
    "}\n",
    "\n",
    "EDA.plot_avg_imgs(batch, with_histogram=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA.plot_global_hist(batch, sample_size=int(len(train_data) ** 0.25))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From which we can see, that color values, especially G and R channels, are similar for majority of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "        \n",
    "\n",
    "def detect_outliers(imgs, labels, test_size=1000):\n",
    "    # Take only subset of data\n",
    "    sample = np.random.choice(len(imgs), test_size, replace=False)\n",
    "    imgs = imgs[sample]\n",
    "    labels = labels[sample]\n",
    "    \n",
    "    # Scale data. For images it is simple, every pixel is in range 0-255.\n",
    "    imgs = imgs / 255\n",
    "    \n",
    "    # Find Outliers using LOF\n",
    "    LOF = LocalOutlierFactor()\n",
    "    outliers = np.where(LOF.fit_predict(imgs) == -1)[0]\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        cat_images = train_data[outliers][train_labels[outliers] == i]\n",
    "        if len(cat_images) == 0:\n",
    "            continue\n",
    "        print(utils.get_label_name(i))\n",
    "        graphs.plot_images(cat_images)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "detect_outliers(train_data, train_labels, test_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found out that there are also images with \"unnatural\" backgrouds.\n",
    "For example clear white background.\n",
    "Some histograms have large bin corresponding to RGB (255, 255, 255)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: same piture multiple times in LOF, what results of histogram say, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
